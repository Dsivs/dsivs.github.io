<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on Call Me Jeff</title><link>https://dsivs.github.io/projects/</link><description>Recent content in Projects on Call Me Jeff</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 01 May 2025 07:07:07 +0100</lastBuildDate><atom:link href="https://dsivs.github.io/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>Distributed Vector Database</title><link>https://dsivs.github.io/projects/distributed_vector_database/</link><pubDate>Thu, 01 May 2025 07:07:07 +0100</pubDate><guid>https://dsivs.github.io/projects/distributed_vector_database/</guid><description>&lt;hr>
&lt;div style="text-align: center;">
 &lt;img src="https://dsivs.github.io/img/DB.png" alt="The workflow of my database" style="max-width: 80%; height: auto;">
&lt;/div>
&lt;p>Designed and implemented a &lt;strong>distributed vector database&lt;/strong> to efficiently store, index, and retrieve high-dimensional vectors across multiple nodes. The system supports &lt;strong>parallel similarity search&lt;/strong> using vector embeddings and ensures scalability and fault tolerance through a &lt;strong>sharded architecture with replication&lt;/strong> . Core features include:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>RPC-based communication&lt;/strong> using gRPC for efficient inter-node messaging.&lt;/li>
&lt;li>&lt;strong>Custom indexing layer&lt;/strong> using &lt;strong>FAISS&lt;/strong> (or HNSW, if applicable) for fast approximate nearest neighbor (ANN) search.&lt;/li>
&lt;li>&lt;strong>Consistent hashing&lt;/strong> for data partitioning and load balancing.&lt;/li>
&lt;li>&lt;strong>Protobuf-based schema&lt;/strong> for defining structured data and query interfaces.&lt;/li>
&lt;li>Integrated &lt;strong>metadata management&lt;/strong> to track vector IDs, versions, and node assignments.&lt;/li>
&lt;li>Optimized for low-latency query responses and horizontal scalability.&lt;/li>
&lt;/ul>
&lt;p>This project demonstrates system design skills in &lt;strong>distributed systems, high-performance computing, and vector search algorithms&lt;/strong> , suitable for applications in recommendation systems, image retrieval, and NLP.&lt;/p></description></item><item><title>Portfolio Optimization</title><link>https://dsivs.github.io/projects/portfolio_optimization/</link><pubDate>Thu, 01 May 2025 07:07:07 +0100</pubDate><guid>https://dsivs.github.io/projects/portfolio_optimization/</guid><description>&lt;hr>
&lt;div style="text-align: center;">
 &lt;img src="https://dsivs.github.io/img/transformer_opt.png" alt="The general workflow" style="max-width: 50%; height: auto;">
&lt;/div>
&lt;p>In recent years, the intersection of machine learning and quantitative finance has opened new opportunities for more accurate and adaptive investment strategies. This project explores the integration of two powerful tools: the &lt;strong>Transformer model&lt;/strong> , a deep learning architecture originally developed for natural language processing, and the &lt;strong>Markowitz portfolio theory&lt;/strong> , a classical framework for risk-return optimization in portfolio management.&lt;/p>
&lt;p>The &lt;strong>Transformer model&lt;/strong> excels at capturing complex, time-dependent patterns in sequential data using a mechanism known as &lt;em>self-attention&lt;/em> . This allows the model to learn relationships between distant points in a sequence without relying on recurrence, making it well-suited for forecasting tasks in financial time series where market signals are often subtle and spread out over time.&lt;/p></description></item></channel></rss>